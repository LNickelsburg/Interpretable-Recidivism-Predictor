{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Imports** ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from interpret.glassbox import ExplainableBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Training and Test Sets** ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = pd.read_csv('train_with_misclass.csv')\n",
    "X_train = training_set.loc[:,:'five_year']\n",
    "y_train = training_set['general_two_year'].values\n",
    "\n",
    "test_set = pd.read_csv('dataset/standardized_testing.csv')\n",
    "X_test = test_set.loc[:,:'five_year']\n",
    "y_test = test_set['general_two_year'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#smote = SMOTE(random_state=42)\n",
    "#X_smote, y_smote = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **CART** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5447570332480819\n"
     ]
    }
   ],
   "source": [
    "#basic cart:\n",
    "cart = DecisionTreeClassifier(random_state=42)\n",
    "cart.fit(X_train, y_train)\n",
    "\n",
    "cart_pred = cart.predict(X_test)\n",
    "cart_accuracy = accuracy_score(y_test, cart_pred)\n",
    "print(\"Accuracy:\", cart_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 320 candidates, totalling 1600 fits\n",
      "Best Hyperparameters: {'max_depth': 5, 'max_leaf_nodes': 10, 'min_samples_leaf': 50, 'min_samples_split': 2}\n"
     ]
    }
   ],
   "source": [
    "#hyperparameter tuning \n",
    "\n",
    "cart_param_grid = {\n",
    "    'max_depth': [1, 5, 10, 100],\n",
    "    'min_samples_split': [2, 5, 10, 20],\n",
    "    'min_samples_leaf': [10, 20, 40, 50, 100],\n",
    "    'max_leaf_nodes': [2, 10, 15, 20]\n",
    "}\n",
    "\n",
    "cart_grid_search = GridSearchCV(estimator=cart, param_grid=cart_param_grid, cv=5, n_jobs=-1, verbose=2, scoring='accuracy')\n",
    "cart_grid_search.fit(X_train, y_train)\n",
    "print(\"Best Hyperparameters:\", cart_grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with Best Hyperparameters: 0.6368286445012787\n"
     ]
    }
   ],
   "source": [
    "#best cart:\n",
    "\n",
    "best_cart = DecisionTreeClassifier(**cart_grid_search.best_params_)\n",
    "best_cart.fit(X_train, y_train)\n",
    "best_cart_pred = best_cart.predict(X_test)\n",
    "best_cart_accuracy = accuracy_score(y_test, best_cart_pred)\n",
    "print(\"Accuracy with Best Hyperparameters:\", best_cart_accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6380525304292121\n"
     ]
    }
   ],
   "source": [
    "best_cart_train = best_cart.predict(X_train)\n",
    "print(accuracy_score(y_train, best_cart_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **EBM** ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6470588235294118\n"
     ]
    }
   ],
   "source": [
    "#basic ebm:\n",
    "ebm = ExplainableBoostingClassifier(random_state=42, n_jobs=-1)\n",
    "ebm.fit(X_train, y_train)\n",
    "\n",
    "ebm_pred = ebm.predict(X_test)\n",
    "ebm_accuracy = accuracy_score(y_test, ebm_pred)\n",
    "print(\"Accuracy:\", ebm_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      "Best Hyperparameters: {'early_stopping_rounds': 10, 'interactions': 5, 'learning_rate': 0.01, 'max_bins': 512, 'max_interaction_bins': 16, 'min_samples_leaf': 10}\n"
     ]
    }
   ],
   "source": [
    "#hyperparameter tuning \n",
    "\n",
    "ebm_param_grid = {\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'max_bins': [256, 512],\n",
    "    'max_interaction_bins': [16, 32, 64],\n",
    "    'interactions': [0, 2, 5],\n",
    "    'min_samples_leaf': [1, 10],\n",
    "    'early_stopping_rounds': [10, 50]\n",
    "}\n",
    "\n",
    "ebm_grid_search = GridSearchCV(estimator=ebm, param_grid=ebm_param_grid, cv=5, n_jobs=-1, verbose=2, scoring='accuracy')\n",
    "ebm_grid_search.fit(X_train, y_train)\n",
    "print(\"Best Hyperparameters:\", ebm_grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with Best Hyperparameters: 0.6445012787723785\n"
     ]
    }
   ],
   "source": [
    "#best ebm:\n",
    "best_ebm = ExplainableBoostingClassifier(**ebm_grid_search.best_params_)\n",
    "best_ebm.fit(X_train, y_train)\n",
    "best_ebm_pred = best_ebm.predict(X_test)\n",
    "best_ebm_accuracy = accuracy_score(y_test, best_ebm_pred)\n",
    "print(\"Accuracy with Best Hyperparameters:\", best_ebm_accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6758488148622678\n"
     ]
    }
   ],
   "source": [
    "best_ebm_train = best_ebm.predict(X_train)\n",
    "print(accuracy_score(y_train, best_ebm_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Linear SVM** ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lnick\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lnick\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.670076726342711\n"
     ]
    }
   ],
   "source": [
    "#basic linear svm:\n",
    "lsvm = LinearSVC(C=1.0, random_state=42)\n",
    "lsvm.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lsvm.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lnick\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'C': 1, 'intercept_scaling': 1, 'loss': 'squared_hinge'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lnick\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#hyperparameter tuning \n",
    "\n",
    "lsvm_param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'intercept_scaling': [0.1, 1, 10],\n",
    "    'loss': ['hinge', 'squared_hinge']\n",
    "}\n",
    "\n",
    "\n",
    "lsvm_grid_search = GridSearchCV(estimator=lsvm, param_grid=lsvm_param_grid, cv=5, n_jobs=-1, verbose=2, scoring='accuracy')\n",
    "lsvm_grid_search.fit(X_train, y_train)\n",
    "print(\"Best Hyperparameters:\", lsvm_grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lnick\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with Best Hyperparameters: 0.6624040920716112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lnick\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#best lsvm:\n",
    "best_lsvm = LinearSVC(**lsvm_grid_search.best_params_)\n",
    "best_lsvm.fit(X_train, y_train)\n",
    "best_lsvm_pred = best_lsvm.predict(X_test)\n",
    "best_lsvm_accuracy = accuracy_score(y_test, best_lsvm_pred)\n",
    "print(\"Accuracy with Best Hyperparameters:\", best_lsvm_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6386931454196029\n"
     ]
    }
   ],
   "source": [
    "best_lsvm_train = best_lsvm.predict(X_train)\n",
    "print(accuracy_score(y_train, best_lsvm_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **XGBoost** ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5959079283887468\n"
     ]
    }
   ],
   "source": [
    "#basic xgboost:\n",
    "xgboost = xgb.XGBClassifier(objective='binary:logistic', random_state=42)\n",
    "xgboost.fit(X_train, y_train)\n",
    "\n",
    "y_pred = xgboost.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 729 candidates, totalling 3645 fits\n",
      "Best Hyperparameters: {'colsample_bytree': 1.0, 'gamma': 10, 'max_depth': 2, 'min_child_weight': 10, 'n_estimators': 250, 'subsample': 0.4}\n"
     ]
    }
   ],
   "source": [
    "#hyperparameter tuning \n",
    "\n",
    "xgb_param_grid = {\n",
    "    'n_estimators': [100, 250, 500], \n",
    "    'max_depth': [2, 5, 10],      \n",
    "    'min_child_weight': [1, 5, 10],  \n",
    "    'subsample': [0.4, 0.6, 0.8],   \n",
    "    'colsample_bytree': [0.5, 0.75, 1.0],\n",
    "    'gamma': [0, 1, 10]       \n",
    "}\n",
    "\n",
    "\n",
    "xgb_grid_search = GridSearchCV(estimator=xgboost, param_grid=xgb_param_grid, cv=5, n_jobs=-1, verbose=2, scoring='roc_auc')\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "print(\"Best Hyperparameters:\", xgb_grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with Best Hyperparameters: 0.6521739130434783\n"
     ]
    }
   ],
   "source": [
    "#best xgb:\n",
    "best_xgb = xgb.XGBClassifier(**xgb_grid_search.best_params_)\n",
    "best_xgb.fit(X_train, y_train)\n",
    "best_xgb_pred = best_xgb.predict(X_test)\n",
    "best_xgb_accuracy = accuracy_score(y_test, best_xgb_pred)\n",
    "print(\"Accuracy with Best Hyperparameters:\", best_xgb_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.649583600256246\n"
     ]
    }
   ],
   "source": [
    "best_xgb_train = best_xgb.predict(X_train)\n",
    "print(accuracy_score(y_train, best_xgb_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Neural Network** ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\lnick\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\lnick\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\lnick\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\lnick\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.3694 - accuracy: 0.5754\n",
      "Accuracy: 0.5754475593566895\n"
     ]
    }
   ],
   "source": [
    "neural_net = Sequential()\n",
    "neural_net.add(Dense(128, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "neural_net.add(Dense(64, activation='relu'))\n",
    "neural_net.add(Dense(1, activation='sigmoid')) #for binary features\n",
    "\n",
    "neural_net.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = neural_net.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=0)\n",
    "\n",
    "loss, accuracy = neural_net.evaluate(X_test, y_test)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(optimizer='adam', activation='relu', neurons=128):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, activation=activation, input_shape=(X_train.shape[1],)))\n",
    "    model.add(Dense(64, activation=activation))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'optimizer': 'sgd', 'activation': 'tanh', 'neurons': 256, 'batch_size': 64, 'epoch': 50}\n"
     ]
    }
   ],
   "source": [
    "#hyperparameter grid\n",
    "optimizers = ['adam', 'adagrad', 'sgd']\n",
    "activations = ['relu', 'tanh']\n",
    "neuron_numbers = [128, 256, 512]\n",
    "batch_sizes = [32, 64]\n",
    "epochs = [10, 50]\n",
    "\n",
    "best_nn_accuracy = 0\n",
    "best_nn_params = {}\n",
    "\n",
    "for optimizer in optimizers:\n",
    "    for activation in activations:\n",
    "        for neurons in neuron_numbers:\n",
    "            for sizes in batch_sizes:\n",
    "                for epoch in epochs:\n",
    "                    # Create and train the model\n",
    "                    nn = create_model(optimizer=optimizer, activation=activation, neurons=neurons)\n",
    "                    nn.fit(X_train, y_train, epochs=epoch, batch_size=sizes, verbose=0)\n",
    "                    \n",
    "                    # Evaluate the model\n",
    "                    loss, accuracy = nn.evaluate(X_test, y_test, verbose=0)\n",
    "                    \n",
    "                    # Compare and store the best parameters\n",
    "                    if accuracy > best_nn_accuracy:\n",
    "                        best_nn_accuracy = accuracy\n",
    "                        best_nn_params = {'optimizer': optimizer, 'activation': activation, 'neurons': neurons,\n",
    "                                          'batch_size': sizes, 'epoch': epoch}\n",
    "\n",
    "print(f\"Best Parameters: {best_nn_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 3ms/step\n",
      "Accuracy with Best Hyperparameters: 0.6726342710997443\n"
     ]
    }
   ],
   "source": [
    "#best nn:\n",
    "best_nn = create_model(optimizer=best_nn_params['optimizer'], activation=best_nn_params['activation'], neurons=best_nn_params['neurons'])\n",
    "best_nn.fit(X_train, y_train, epochs=epoch, batch_size=sizes, verbose=0)\n",
    "\n",
    "best_nn_pred = best_nn.predict(X_test)\n",
    "best_nn_pred = (best_nn_pred > 0.5).astype(int).ravel()\n",
    "best_nn_accuracy = accuracy_score(y_test, best_nn_pred)\n",
    "print(\"Accuracy with Best Hyperparameters:\", best_nn_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 0s 3ms/step\n",
      "0.6483023702754644\n"
     ]
    }
   ],
   "source": [
    "best_nn_train = best_nn.predict(X_train)\n",
    "best_nn_train = (best_nn_train > 0.5).astype(int).ravel()\n",
    "print(accuracy_score(y_train, best_nn_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **count misclassifications of the training set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2731\n"
     ]
    }
   ],
   "source": [
    " \n",
    "misclassification_count = 0\n",
    "for i in range(len(y_train)):\n",
    "    \n",
    "    # Compare predictions with true label for each model\n",
    "    if best_cart_train[i] != y_train[i]:\n",
    "        misclassification_count += 1\n",
    "    if best_ebm_train[i] != y_train[i]:\n",
    "        misclassification_count += 1\n",
    "    if best_lsvm_train[i] != y_train[i]:\n",
    "        misclassification_count += 1\n",
    "    if best_xgb_train[i] != y_train[i]:\n",
    "        misclassification_count += 1\n",
    "    if best_nn_train[i] != y_train[i]:\n",
    "        misclassification_count += 1\n",
    "\n",
    "print(misclassification_count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
